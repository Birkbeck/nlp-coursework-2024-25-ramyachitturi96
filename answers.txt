Answers to the text questions go here.

Part One 
d - When is the Flesch Kincaid score *not* a valid, robust or reliable estimator of text difficulty? Give two conditions. 

The Flesh Kincaid score is not valid, robust or reliable estimator of text difficulty:
1. When the text includes complex or domain specific vocabulary- The formula is only based on length of the sentence, 
length of the words and syllables count but not on reader familarity with the content. As a result, if a book using short and simple sentences 
might get low fk score, even though understanding its emotional depth or terminology requires maturity and subject knowledge.
2. When text is not in standard english or in different style - The score assumes standard grammar and structure. It may miscalculate, 
readability of text for broken grammar, poetry, informal speech or creative writing with unsual structure.


Part two
f - Explain your tokenizer function and discuss its performance.

I have used spacy tokenizer which we have used in the first part of the assignment, and apply specific filters to extract only meaningful
tokens for text analysis.

Using spacy tokenizer nlp(text) processes the input string and returns a Doc objects.
This object automatically clean up the data like splitting the text into words, remove stopwords, punctuations and part-of-speech...
I collected the tokens only made of alphabetic charecters and deleted numbers, special charactes, punctuations, stopwords... by using token.is_alpha
I filtered for tokens that belong to key parts of speech like NOUN, ADJECTIVE, ADVERB, VERB as they tend to carry more semantic meaning.

Also used below parameters to vectorizer: 
min_df=20 - to delete the tokens which are not present in atleast 20 speeches or rows, 
max_df=0.7 - to delete the token which are in 70% of the documents.

I passed my tokenizer to TFidfvectorizer and then perform the next step, tarining the models and print classification report but i have 
observed performance got degraded and efficiency also decreased as the runtime has increase due to the custom tokenizer.

I tried with both models, SVM and Random Forest by using parameter n-gram as default and also changing the parameter n-gram to (1,3)
so that it will take uni-gram, bi-gram and tri-gram but still performance has not increased.

1. Below are the values for both the models with default n-grams (1,1)
Random Forest Model:
Macro-average f1 score: 0.45469001950616234
Classification Report:
                         precision    recall  f1-score   support

           Conservative       0.72      0.98      0.83       964
                 Labour       0.75      0.44      0.56       463
       Liberal Democrat       0.00      0.00      0.00        54
Scottish National Party       0.87      0.29      0.43       136

               accuracy                           0.73      1617
              macro avg       0.59      0.43      0.45      1617
           weighted avg       0.72      0.73      0.69      1617

SVM Model:
Macro-average f1 score: 0.5933446121140653
Classification Report:
                         precision    recall  f1-score   support

           Conservative       0.83      0.92      0.87       964
                 Labour       0.74      0.71      0.72       463
       Liberal Democrat       1.00      0.07      0.14        54
Scottish National Party       0.78      0.54      0.64       136

               accuracy                           0.80      1617
              macro avg       0.84      0.56      0.59      1617
           weighted avg       0.81      0.80      0.79      1617

2. Below are the values for both the models using n-grams as (1,3) - uni-gram, bi-gram and tri-gram.
We compared to default n-gram, the performance slightly increased for uni-gram, bi-gram and tri-gram.

Random Forest Model:
Macro-average f1 score: 0.47930475175651455
Classification Report:
                         precision    recall  f1-score   support

           Conservative       0.74      0.96      0.83       964
                 Labour       0.75      0.48      0.58       463
       Liberal Democrat       0.00      0.00      0.00        54
Scottish National Party       0.84      0.35      0.50       136

               accuracy                           0.74      1617
              macro avg       0.58      0.45      0.48      1617
           weighted avg       0.72      0.74      0.71      1617

SVM Model:
Macro-average f1 score: 0.5854220473255666
Classification Report:
                         precision    recall  f1-score   support

           Conservative       0.84      0.92      0.88       964
                 Labour       0.75      0.73      0.74       463
       Liberal Democrat       1.00      0.04      0.07        54
Scottish National Party       0.78      0.56      0.65       136

               accuracy                           0.81      1617
              macro avg       0.84      0.56      0.59      1617
           weighted avg       0.81      0.81      0.79      1617

3. Below are the values for customer tokenizer using default n-gram:
Performance decreased and runtime also increased so effieciency decreased.

Random Forest Model:
Macro-average f1 score: 0.4010445940798477
Classification Report:
                         precision    recall  f1-score   support

           Conservative       0.69      0.98      0.81       964
                 Labour       0.76      0.38      0.51       463
       Liberal Democrat       0.00      0.00      0.00        54
Scottish National Party       0.92      0.17      0.29       136

               accuracy                           0.71      1617
              macro avg       0.59      0.38      0.40      1617
           weighted avg       0.71      0.71      0.65      1617

SVM Model:
Macro-average f1 score: 0.5755080221074028
Classification Report:
                         precision    recall  f1-score   support

           Conservative       0.81      0.92      0.86       964
                 Labour       0.72      0.67      0.69       463
       Liberal Democrat       1.00      0.06      0.11        54
Scottish National Party       0.79      0.54      0.64       136

               accuracy                           0.79      1617
              macro avg       0.83      0.55      0.58      1617
           weighted avg       0.79      0.79      0.77      1617

Duration for default n-gram: 797.6876513957977

4. Below are the values for customer tokenizer using n-gram as (1,3) - uni-gram, bi-gram and tri-gram
I observed similar performance but efficiency decreased.

andom Forest Model:
Macro-average f1 score: 0.4697235901804915
Classification Report:
                         precision    recall  f1-score   support

           Conservative       0.73      0.97      0.83       964
                 Labour       0.74      0.46      0.56       463
       Liberal Democrat       0.00      0.00      0.00        54
Scottish National Party       0.84      0.34      0.48       136

               accuracy                           0.74      1617
              macro avg       0.58      0.44      0.47      1617
           weighted avg       0.72      0.74      0.70      1617

SVM Model:
Macro-average f1 score: 0.5768486648176033
Classification Report:
                         precision    recall  f1-score   support

           Conservative       0.83      0.93      0.88       964
                 Labour       0.74      0.71      0.73       463
       Liberal Democrat       0.00      0.00      0.00        54
Scottish National Party       0.85      0.60      0.70       136

               accuracy                           0.81      1617
              macro avg       0.61      0.56      0.58      1617
           weighted avg       0.78      0.81      0.79      1617

Duration for 3-gram: 849.3814244270325

So, i conclude the performance and  efficiency are good while using basic model without any custom tokenizer and parameters